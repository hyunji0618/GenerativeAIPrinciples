{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Self-Attention from Scratch\n",
    "\n",
    "**University of Chicago**\n",
    "**MS in Applied Data Science**\n",
    "\n",
    "Course: Generative AI Principles \n",
    "\n",
    "Date: 04/12/2025\n",
    "\n",
    "Author: Hyunji Amy Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Self-Attention with the Sentence: `Attention is all I want`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Embeddings:\n",
      " tensor([[-0.0746,  0.4155,  0.2370,  1.6803,  0.7327],\n",
      "        [-2.0189,  1.0442,  0.3381, -1.4512,  0.7652],\n",
      "        [ 0.0567,  0.2368, -0.7948,  0.9124, -1.6907],\n",
      "        [ 0.5113,  0.5540,  1.4801,  0.1500,  0.5684],\n",
      "        [ 0.0543, -1.1792,  0.3507,  0.9551, -1.1919]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the sentence\n",
    "sentence = [\"Attention\", \"is\", \"all\", \"I\", \"want\"]\n",
    "\n",
    "# Random embeddings (5 words, embedding_dim = 5)\n",
    "embedding_dim = 5\n",
    "X = torch.randn(len(sentence), embedding_dim)\n",
    "print(\"Input Embeddings:\\n\", X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q (Queries):\n",
      " tensor([[ 2.1723, -4.0897, -1.6131, -3.8406,  1.3050],\n",
      "        [-1.8730,  0.3589, -0.1468,  4.8753,  3.8092],\n",
      "        [ 2.7073, -0.3493,  4.0005, -1.7202, -1.7189],\n",
      "        [-0.1079,  0.9960, -2.5889, -2.0714,  2.0842],\n",
      "        [ 1.8063,  2.1203,  3.0218, -1.7957, -0.5332]])\n",
      "K (Keys):\n",
      " tensor([[-0.7547,  1.5232, -0.2677,  4.2794,  2.9533],\n",
      "        [-0.0593,  5.6631,  3.2016, -1.9919, -0.1876],\n",
      "        [ 0.0085,  0.5185,  2.1455,  1.4653,  0.2435],\n",
      "        [-1.8395, -0.5692, -2.0098,  0.1412, -0.5648],\n",
      "        [ 0.8019, -1.6537, -2.1741,  0.2582,  0.5619]])\n",
      "V (Values):\n",
      " tensor([[ 1.4189,  1.0085,  1.5257, -2.2394,  1.7026],\n",
      "        [ 0.7037,  2.2170, -4.8454, -0.6505,  3.2561],\n",
      "        [ 2.2393, -3.0601, -0.7219, -0.5894, -4.2082],\n",
      "        [-1.4294,  2.6288,  2.8391,  1.9880,  0.3836],\n",
      "        [-0.8575,  1.2128,  1.8411,  0.6046, -1.5518]])\n"
     ]
    }
   ],
   "source": [
    "# Random projection matrices for query, key, value\n",
    "W_q = torch.randn(embedding_dim, embedding_dim)\n",
    "W_k = torch.randn(embedding_dim, embedding_dim)\n",
    "W_v = torch.randn(embedding_dim, embedding_dim)\n",
    "\n",
    "# Compute Q, K, V\n",
    "Q = X @ W_q\n",
    "K = X @ W_k\n",
    "V = X @ W_v\n",
    "\n",
    "print(\"Q (Queries):\\n\", Q)\n",
    "print(\"K (Keys):\\n\", K)\n",
    "print(\"V (Values):\\n\", V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Scores:\n",
      " tensor([[-8.9529, -9.4131, -4.8624,  0.1317,  5.2565],\n",
      "        [15.2558, -3.9142,  3.5449,  0.9271,  0.7258],\n",
      "        [-7.1931,  6.4480,  2.4533, -5.4083, -3.2910],\n",
      "        [-0.1868,  0.4890, -3.3839,  1.5048,  2.0264],\n",
      "        [-3.6679, 11.2929,  2.1632, -4.7205, -4.1997]])\n",
      "Attention Weights:\n",
      " tensor([[6.7043e-07, 4.2314e-07, 4.0068e-05, 5.9116e-03, 9.9405e-01],\n",
      "        [9.9999e-01, 4.7269e-09, 8.2038e-06, 5.9862e-07, 4.8946e-07],\n",
      "        [1.1690e-06, 9.8185e-01, 1.8080e-02, 6.9651e-06, 5.7872e-05],\n",
      "        [5.6886e-02, 1.1181e-01, 2.3254e-03, 3.0878e-01, 5.2020e-01],\n",
      "        [3.1808e-07, 9.9989e-01, 1.0838e-04, 1.1102e-07, 1.8688e-07]])\n"
     ]
    }
   ],
   "source": [
    "# Compute attention scores\n",
    "scores = Q @ K.T / (embedding_dim ** 0.5)\n",
    "print(\"Attention Scores:\\n\", scores)\n",
    "\n",
    "# Softmax to get attention weights\n",
    "attention_weights = F.softmax(scores, dim=-1)\n",
    "print(\"Attention Weights:\\n\", attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Output:\n",
      " tensor([[-0.8608,  1.2210,  1.8469,  0.6127, -1.5404],\n",
      "        [ 1.4189,  1.0084,  1.5257, -2.2394,  1.7026],\n",
      "        [ 0.7313,  2.1215, -4.7704, -0.6493,  3.1208],\n",
      "        [-0.7229,  1.7407,  1.3778,  0.7268, -0.2377],\n",
      "        [ 0.7038,  2.2164, -4.8449, -0.6505,  3.2552]])\n"
     ]
    }
   ],
   "source": [
    "# Final attention output\n",
    "output = attention_weights @ V\n",
    "print(\"Attention Output:\\n\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Change the input embeddings \n",
    "Change the input embeddings by manually defining the embedding matrix and see the shift of attention\n",
    "\n",
    "Why does attention shift? What token is most influential?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually define the random embedding matrix\n",
    "# X_s: Shifted embeddings\n",
    "X_s = torch.tensor([\n",
    "    [1.0, 0.5, 0.2, 0.1, 0.0],   # \"Attention\"\n",
    "    [0.9, 0.8, 0.1, 0.0, 0.2],   # \"is\"\n",
    "    [0.3, 0.4, 0.9, 0.7, 0.6],   # \"all\"\n",
    "    [0.5, 0.1, 0.8, 0.6, 0.3],   # \"I\"\n",
    "    [0.1, 0.9, 0.5, 0.3, 0.7]    # \"want\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q (Queries):\n",
      " tensor([[ 0.1278, -0.0744, -1.3728, -1.7819, -0.7519],\n",
      "        [-0.0220, -0.7233, -1.7965, -1.5250, -0.5378],\n",
      "        [ 0.6921, -0.9226, -2.0855, -2.5776,  1.5408],\n",
      "        [ 0.5961, -0.0968, -1.4975, -2.4091,  0.8164],\n",
      "        [ 0.2743, -1.6352, -2.1738, -1.4755,  1.4491]])\n",
      "K (Keys):\n",
      " tensor([[-1.2069, -1.6294, -0.4443,  0.3548, -0.9463],\n",
      "        [-1.3857, -0.9587,  0.2312,  0.5417, -0.8783],\n",
      "        [-1.2489,  0.0588, -1.3544,  1.6218,  0.7636],\n",
      "        [-0.9667, -0.9026, -1.7495,  1.0479,  0.3172],\n",
      "        [-1.3564,  1.1733,  0.3046,  1.4131,  0.4736]])\n",
      "V (Values):\n",
      " tensor([[-0.1617, -1.1076,  1.8366,  1.1813, -1.7171],\n",
      "        [ 0.2512, -1.3916,  1.2984,  0.8606, -1.4310],\n",
      "        [-0.3607,  1.8313,  2.2421,  0.2999,  0.8723],\n",
      "        [-0.7278,  1.4560,  2.4949,  0.7395,  0.1645],\n",
      "        [ 0.4903,  0.6724,  0.7186, -0.1424,  0.7800]])\n"
     ]
    }
   ],
   "source": [
    "# Compute Q, K, V\n",
    "Q = X_s @ W_q\n",
    "K = X_s @ W_k\n",
    "V = X_s @ W_v\n",
    "\n",
    "print(\"Q (Queries):\\n\", Q)\n",
    "print(\"K (Keys):\\n\", K)\n",
    "print(\"V (Values):\\n\", V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Scores:\n",
      " tensor([[ 0.2934, -0.3256, -0.7910,  0.1071, -1.5890],\n",
      "        [ 0.8814, -0.0203, -0.2083,  0.9161, -1.6886],\n",
      "        [-0.3479, -1.4786, -0.4909,  0.7155, -2.4906],\n",
      "        [-0.6814, -1.3870, -0.8970, -0.0602, -1.9660],\n",
      "        [ 0.6280, -0.6203,  0.5451,  1.7563, -1.9461]])\n",
      "Attention Weights:\n",
      " tensor([[0.3498, 0.1883, 0.1183, 0.2903, 0.0532],\n",
      "        [0.3504, 0.1422, 0.1178, 0.3627, 0.0268],\n",
      "        [0.1922, 0.0620, 0.1666, 0.5566, 0.0226],\n",
      "        [0.2253, 0.1113, 0.1816, 0.4194, 0.0624],\n",
      "        [0.1861, 0.0534, 0.1713, 0.5750, 0.0142]])\n"
     ]
    }
   ],
   "source": [
    "# Compute attention scores\n",
    "scores = Q @ K.T / (embedding_dim ** 0.5)\n",
    "print(\"Attention Scores:\\n\", scores)\n",
    "\n",
    "# Softmax to get attention weights\n",
    "attention_weights = F.softmax(scores, dim=-1)\n",
    "print(\"Attention Weights:\\n\", attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Output:\n",
      " tensor([[-0.2371,  0.0256,  1.9148,  0.8179, -0.6777],\n",
      "        [-0.3143,  0.1760,  2.0166,  0.8361, -0.6218],\n",
      "        [-0.4696,  0.8314,  2.2120,  0.7388, -0.1644],\n",
      "        [-0.3487,  0.5808,  2.0567,  0.7177, -0.2701],\n",
      "        [-0.4900,  0.8800,  2.2400,  0.7404, -0.1409]])\n"
     ]
    }
   ],
   "source": [
    "# Final attention output\n",
    "output = attention_weights @ V\n",
    "print(\"Attention Output:\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
