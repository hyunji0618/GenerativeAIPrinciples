{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYapTjoYa0kO"
   },
   "source": [
    "# Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8HDKzBai5dL"
   },
   "source": [
    "### History\n",
    "\n",
    "2018 was a breakthrough year in NLP. \n",
    "\n",
    "Transfer learning, particularly models like Allen AI's ELMO, OpenAI's Open-GPT, and Google's BERT allowed researchers to smash multiple benchmarks with minimal task-specific fine-tuning and provided the rest of the NLP community with pretrained models that could easily (with less data and less compute time) be fine-tuned and implemented to produce state-of-the-art results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WoitNQMWA1bt"
   },
   "source": [
    "### What is BERT?\n",
    "\n",
    "**BERT (Bidirectional Encoder Representations from Transformers)** is a method of pretraining language representations that was used to create models that we can then download and use for free. \n",
    "\n",
    "You can either use these models to extract high quality language features from your text data, or you can fine-tune these models on a specific task (classification, entity recognition, question answering, etc.) with your own data to produce predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-dDVmXAA3At"
   },
   "source": [
    "### Why BERT embeddings?\n",
    "\n",
    "BERT can be used to **extract features, namely word and sentence embedding vectors, from text data**. What can we do with these word and sentence embedding vectors? \n",
    "\n",
    "First, these embeddings are useful for `keyword/search expansion, semantic search and information retrieval`. For example, if you want to match customer questions or searches against already answered questions or well documented searches, these representations will help you accurately retrieve results matching the customer's intent and contextual meaning, even if there's no keyword or phrase overlap.\n",
    "\n",
    "Second, and perhaps more importantly, these vectors are used as `high-quality feature inputs to downstream models`. NLP models such as LSTMs or CNNs require inputs in the form of numerical vectors, and this typically means translating features like the vocabulary and parts of speech into numerical representations. In the past, words have been represented either as uniquely indexed values (one-hot encoding), or more helpfully as neural word embeddings where vocabulary words are matched against the fixed-length feature embeddings that result from models like Word2Vec or Fasttext. BERT offers an advantage over models like Word2Vec, because while each word has a fixed representation under Word2Vec regardless of the context within which the word appears, **BERT produces word representations that are dynamically informed by the words around them**. For example, given two sentences:\n",
    "\n",
    "- \"The man was accused of robbing a bank.\"\n",
    "- \"The man went fishing by the bank of the river.\"\n",
    "\n",
    "Word2Vec would produce the same word embedding for the word \"bank\" in both sentences, while under BERT the word embedding for \"bank\" would be different for each sentence. Aside from capturing obvious differences, the **context-informed word embeddings** capture other forms of information that result in more accurate feature representations, which in turn results in better model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pqa-7WXBAw8q"
   },
   "source": [
    "## 1. Loading Pre-Trained BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCdqJCtQN52l"
   },
   "source": [
    "Install the pytorch interface for BERT by Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RfUN_KolV-f",
    "outputId": "c0f0cf96-0d7b-4d13-e646-f51c6abad1fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.50.3)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hyunjikim/Library/Python/3.13/lib/python/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (2025.1.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSXImOxMPdNg"
   },
   "source": [
    "Now import `pytorch`, `the pretrained BERT model`, and a `BERT tokenizer`.\n",
    "\n",
    "BERT model is the pre-trained model released by Google that ran on Wikipedia and [Book Corpus](https://arxiv.org/pdf/1506.06724.pdf), a dataset containing +10,000 books of different genres. Google released a few variations of BERT models, but the one we'll use here is the smaller of the two available sizes (\"base\" and \"large\") and ignores casing, hence \"uncased.\"\n",
    "\n",
    "`transformers` provides a number of classes for applying BERT to different tasks (token classification, text classification, ...). Here, we're using the basic `BertModel` which has no specific output task, it's just used for embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254,
     "referenced_widgets": [
      "1d69c12e99b647ef819fad6fcda7f0de",
      "f1266849551443f28bf5d182b8a8ebda",
      "4740320adcbc4293ba4f48423d10d176",
      "1d9c8b62fe7143429369d949f8e45bcb",
      "a3e98e707b4644bb814406d465c44278",
      "39180b1a2c4d448e8ed5531f5dd95f8d",
      "48a392d96be64c2abda1de1f93b5c930",
      "4141fcb79a8645ff8486410d2cb297ab",
      "47c5ac5b052443b488ce7c93622b594f",
      "4c943e8fa7d64e8f92a96bba3ca7a3cc",
      "21bedfc6869046d8bc8af6784bf2905b",
      "7f51ceacda4c4b75a9df6ab43afe9df9",
      "721613d206ff42a6a5e177e89793748c",
      "391a563da8974a59b5cc3b29d38da133",
      "38245b96fde64341bcda116bb0c9a8b5",
      "72f21ea582194c73acc2cb1980d76b48",
      "e557e740d2994c27a3d2513df8311217",
      "b113e12db4c042c0b1494aaa03a78793",
      "4eca4af3dbb74c1eba5b212ee967def7",
      "038b3b6907df47d186eaa618b27c9e01",
      "dcd1a84e56a34e2f9d32969982e8f8a4",
      "0eff92cf040f48e686e342701c8433be",
      "57f7de73a87c47c0a1e80a981da09297",
      "4852502fc965406f96fcea54d8043dba",
      "eaf4f4bf3ff84f9d90a1f01f0e25a45c",
      "ade4e04af73c463b8ba128227e9923e7",
      "4fddf1e099df41c396d79cdab4871c71",
      "5400adc121494e9b85492d23e8916941",
      "ec1da44c139c402f8ca9493e8ca7e076",
      "99dada16ccc0406fa64464145be74a4b",
      "269216a76cec47da99d4102861b415a6",
      "bb83d6f0bb90456489c47f2c391c24d1",
      "b44f74006e9c431bb9fe84a9b6aa241a",
      "d1ce9d63b03f420e828dd1017fe9cee3",
      "8385d43710df4b228bdaa01fe594bf8e",
      "88ecf850c0e946e58e5fb150f9e163ee",
      "548880bd58b74595816ad35671d48eaf",
      "98f29b52392e4360a6f8d07c50064cde",
      "646fe8a8ebb2489193d7ad6032e99950",
      "11cc2d4721be49faa7c05532b5afd4af",
      "1c4976bcfa6c484b834b7b4c89f32207",
      "14162301f7714988b042483e1684b2df",
      "a26def309f6a4d1fb4a52b97f75a3dda",
      "33d034013cc04b9dbb792d259725086f"
     ]
    },
    "id": "lJEnBJ3gHTsQ",
    "outputId": "5086231e-25ed-487f-9252-e7db1cc4c7d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tlv3VlPnKKHN"
   },
   "source": [
    "## 2. Input Formatting\n",
    "Because BERT is a pretrained model that expects input data in a specific format, we need:\n",
    "\n",
    "1. A **special token, `[SEP]`,** to mark the end of a sentence, or the separation between two sentences\n",
    "2. A **special token, `[CLS]`,** at the beginning of our text. This token is used for classification tasks, but BERT expects it no matter what your application is.\n",
    "3. Tokens that conform with the fixed vocabulary used in BERT\n",
    "4. The **Token IDs** for the tokens, from BERT's tokenizer\n",
    "5. **Mask IDs** to indicate which elements in the sequence are tokens and which are padding elements\n",
    "6. **Segment IDs** used to distinguish different sentences\n",
    "7. **Positional Embeddings** used to show token position within the sequence\n",
    "\n",
    "`transformers` interface takes care of all of the above requirements using the `tokenizer.encode_plus` function. (We will go through most of these manually here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diVtyCJCurxJ"
   },
   "source": [
    "### 2.1. Special Tokens\n",
    "The special token `[SEP]` is used to differentiate sentences. \n",
    "\n",
    "The `[CLS]` token always appears at the start of the text.\n",
    "\n",
    "Both tokens are **always required**, even if we only have one sentence, and even if we are not using BERT for classification. \n",
    "\n",
    "**2 Sentence Input**:\n",
    "\n",
    "`[CLS] The man went to the store. [SEP] He bought a gallon of milk.`\n",
    "\n",
    "**1 Sentence Input**:\n",
    "\n",
    "`[CLS] The man went to the store. [SEP]`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gsyrAwYvBfC"
   },
   "source": [
    "### 2.2. Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WafgQPLAWmo"
   },
   "source": [
    "BERT provides its own tokenizer, `BertTokenizer`, which we imported above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pg0P9rFxJwwp",
    "outputId": "2925dcc3-83a5-4363-ef7b-11ca7cd40ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Tokenize our sentence with the BERT tokenizer.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "print (tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q51eN4KAkbIJ"
   },
   "source": [
    "The word **\"embeddings\"** is tokenized as:\n",
    "\n",
    "`['em', '##bed', '##ding', '##s']`\n",
    "\n",
    "The original word has been split into smaller subwords and characters. **'##'** are BERT tokenizer's way to denote that this subword or character is part of a larger word and preceded by another subword.  \n",
    "\n",
    "Why does it look this way? This is because the BERT tokenizer was created with a WordPiece model. This model creates a fixed-size vocabulary of individual characters, subwords, and words that best fits our language data. The WordPiece model generated a vocabulary that contains all English characters plus the most common words and subwords. This contains:\n",
    "\n",
    "1. Whole words\n",
    "2. Subwords occuring at the front of a word or in isolation (\"em\" as in \"embeddings\" is assigned the same vector as the standalone sequence of characters \"em\" as in \"go get em\" )\n",
    "3. Subwords not at the front of a word, which are preceded by '##' to denote this case\n",
    "4. Individual characters\n",
    "\n",
    "To tokenize a word under this model, the tokenizer first checks if the whole word is in the vocabulary. If not, it tries to break the word into the largest possible subwords contained in the vocabulary, and as a last resort will decompose the word into individual characters. Then we can represent a word as the collection of its individual characters.\n",
    "\n",
    "Splitting into subword tokens ['em', '##bed', '##ding', '##s'] will retain some of the contextual meaning of the original word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jp5zXAPBVp82"
   },
   "source": [
    "Some examples of the tokens contained in the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1z1SzuTrqx-7",
    "outputId": "52777895-9790-4f6b-b0cf-c2d4a05f0fef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knight',\n",
       " 'lap',\n",
       " 'survey',\n",
       " 'ma',\n",
       " '##ow',\n",
       " 'noise',\n",
       " 'billy',\n",
       " '##ium',\n",
       " 'shooting',\n",
       " 'guide',\n",
       " 'bedroom',\n",
       " 'priest',\n",
       " 'resistance',\n",
       " 'motor',\n",
       " 'homes',\n",
       " 'sounded',\n",
       " 'giant',\n",
       " '##mer',\n",
       " '150',\n",
       " 'scenes']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.vocab.keys())[5000:5020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoF3LC47VgBb"
   },
   "source": [
    "After breaking the text into tokens, we then have to convert the sentence from a `list of strings` to a `list of vocabulary indeces`.\n",
    "\n",
    "The example sentence below contains two instances of the word `\"bank\"` with different meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XYjcYJuXoAQx",
    "outputId": "89ef1f1d-d26b-433c-d408-1e17fe7c8ee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "after         2,044\n",
      "stealing     11,065\n",
      "money         2,769\n",
      "from          2,013\n",
      "the           1,996\n",
      "bank          2,924\n",
      "vault        11,632\n",
      ",             1,010\n",
      "the           1,996\n",
      "bank          2,924\n",
      "robber       27,307\n",
      "was           2,001\n",
      "seen          2,464\n",
      "fishing       5,645\n",
      "on            2,006\n",
      "the           1,996\n",
      "mississippi   5,900\n",
      "river         2,314\n",
      "bank          2,924\n",
      ".             1,012\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
    "text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
    "       \"fishing on the Mississippi river bank.\"\n",
    "\n",
    "# Add the special tokens.\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "if6C_iCULU60"
   },
   "source": [
    "### 2.3 Segment ID\n",
    "BERT is trained on and expects sentence pairs, `using 1s and 0s to distinguish between the two sentences`. That is, for each token in \"tokenized_text,\" we must specify which sentence it belongs to: sentence 0 (a series of 0s) or sentence 1 (a series of 1s). \n",
    "\n",
    "**Single-sentence** inputs only require a series of 1s, so we create a vector of 1s for each token in our input sentence.\n",
    "\n",
    "For **two sentences**, assign each word in the first sentence plus the '[SEP]' token a 0, and all tokens of the second sentence a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u_jEkVKxJMc0",
    "outputId": "8cda2175-d617-4bd0-b464-ce2458e31b21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-nY9LASLr2L"
   },
   "source": [
    "## 3. Extracting Embeddings\n",
    "### 3.1. Running BERT on the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Nvaw46mfc8M"
   },
   "source": [
    "Next we convert our data to `torch tensors` and `call the BERT model`. (BERT PyTorch interface requires that the data be in torch tensors rather than Python lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "E_t4cM6KLc98"
   },
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2044, 11065,  2769,  2013,  1996,  2924, 11632,  1010,  1996,\n",
       "          2924, 27307,  2001,  2464,  5645,  2006,  1996,  5900,  2314,  2924,\n",
       "          1012,   102]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCIGe0AXfg4Z"
   },
   "source": [
    "Calling `from_pretrained` will fetch the model from the internet. When we load the `bert-base-uncased`, we see the definition of the model printed in the logging. The model is a deep neural network with 12 layers. \n",
    "\n",
    "`model.eval()` puts our model in evaluation mode as opposed to training mode. Evaluation mode turns off dropout regularization which is used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 798,
     "referenced_widgets": [
      "ac1a9eda3fe441638a55fd83cdde83ba",
      "db9c604c6c0f42dbb4569f8e47238822",
      "83f26150c1c846b0834138bc3cf09f80",
      "4a6b7b9a9fad46f8928b53fc63033047",
      "fcb1c69295e34a0dbb84721213cafb0b",
      "5b4ef18f04cf4e01afab3dbb243273bb",
      "8c73e03d59c64595a835747550e520a0",
      "27912c81ca164a91b8ee2a3c31ced444",
      "8df713d63e5249f3956003e0b8583833",
      "fbd45bf1a1a64e5dabd2560af2128ba5",
      "d35047bf8f584528a0115bbe0ef945ad"
     ]
    },
    "id": "Mq2PKplWfbFv",
    "outputId": "143df20e-b569-45b3-99bf-6bf5ad31f0cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4Qa5KkkM2Aq"
   },
   "source": [
    "Let's evaluate BERT on our example text, and fetch the hidden states of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "nN0QTZwiMzeq"
   },
   "outputs": [],
   "source": [
    "# Run the text through BERT, and collect all hidden states produced from 12 layers\n",
    "with torch.no_grad():\n",
    "\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "    # Evaluating the model will return a different number of objects based on\n",
    "    # how it's configured in the `from_pretrained` call earlier. In this case,\n",
    "    # we set `output_hidden_states = True`, so the third item will be the\n",
    "    # hidden states from all layers. \n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeQNEFbUgMSf"
   },
   "source": [
    "### 3.2. Understanding the Output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKTlTS_sfuAe"
   },
   "source": [
    "The full set of hidden states for this model is stored in `hidden_states`. This object has four dimensions, in the following order:\n",
    "\n",
    "1. The layer number (13 layers)\n",
    "2. The batch number (1 sentence)\n",
    "3. The word / token number (22 tokens in our sentence)\n",
    "4. The hidden unit / feature number (768 features)\n",
    "\n",
    "It's 13 layers because the first element is the input embeddings, the rest is the outputs of each of BERT's 12 layers.\n",
    "\n",
    "The second dimension (batch size) is used when submitting multiple sentences to the model at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eI_uxiW7eRWA",
    "outputId": "22e725de-6d70-4cba-c8e5-aefd3e7a4d21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
      "Number of batches: 1\n",
      "Number of tokens: 22\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Uc_S_hmOWe7"
   },
   "source": [
    "Let's take a quick look at the range of values for a given layer and token.\n",
    "\n",
    "The range is fairly similar for all layers and tokens, with the majority of values falling between \\[-2, 2\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 830
    },
    "id": "-UF_OAO-S1sP",
    "outputId": "1e991b85-bece-44ac-c388-29d9aed28768"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the 5th token in our sentence, select its feature values from layer 5.\n",
    "token_i = 5\n",
    "layer_i = 5\n",
    "vec = hidden_states[layer_i][batch_i][token_i]\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n194RcReDYfw"
   },
   "source": [
    "For our purposes, we want to group by each token.\n",
    "\n",
    "Current dimensions:\n",
    "\n",
    "`[# layers, # batches, # tokens, # features]`\n",
    "\n",
    "Desired dimensions:\n",
    "\n",
    "`[# tokens, # layers, # features]`\n",
    "\n",
    "`permute` function in PyTorch rearranges the dimensions of a tensor.\n",
    "\n",
    "(The first dimension is currently a Python list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0CcY_oRwcHlS",
    "outputId": "83d32634-62d0-4d72-946a-70178acb8f56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Type of hidden_states:  <class 'tuple'>\n",
      "Tensor shape for each layer:  torch.Size([1, 22, 768])\n"
     ]
    }
   ],
   "source": [
    "# `hidden_states` is a Python list.\n",
    "print('      Type of hidden_states: ', type(hidden_states))\n",
    "\n",
    "# Each layer in the list is a torch tensor.\n",
    "print('Tensor shape for each layer: ', hidden_states[0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yXZjLSke3F0"
   },
   "source": [
    "Combine the layers to make one whole big tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pTJV8AFFcLbL",
    "outputId": "6c34bbf4-3d5a-428b-a6a4-4bc8ee519cc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1, 22, 768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the tensors for all layers\n",
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "En4JZ41fh6CI",
    "outputId": "401892db-945d-4921-ab0d-01ad2b59a014"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 22, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the \"batches\" dimension since we don't need it\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CFeqB3ScT4Av",
    "outputId": "904a4948-30fa-496f-a75a-76836a8f5aa9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 22, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
       "           3.8253e-02,  1.6400e-01],\n",
       "         [ 2.3295e-01,  1.3898e-01,  2.9788e-01,  ..., -6.5465e-02,\n",
       "           8.8849e-01,  5.1089e-01],\n",
       "         [ 2.2572e-01, -7.1647e-01, -7.2547e-01,  ...,  4.8439e-01,\n",
       "           6.0302e-01, -9.5701e-02],\n",
       "         ...,\n",
       "         [-3.7402e-02, -6.1545e-01, -1.4419e+00,  ...,  7.9256e-02,\n",
       "          -8.1097e-02, -3.8018e-01],\n",
       "         [-2.2755e-02,  4.2067e-01, -3.2878e-01,  ...,  4.4641e-01,\n",
       "           5.1775e-01,  5.5010e-01],\n",
       "         [-2.3496e-01,  1.5656e-01, -4.6245e-02,  ..., -4.2065e-01,\n",
       "           3.0737e-01, -2.2883e-01]],\n",
       "\n",
       "        [[ 5.2195e-02,  5.9527e-02, -2.1788e-01,  ...,  2.2799e-01,\n",
       "          -7.1235e-02,  1.4849e-02],\n",
       "         [ 3.8188e-01,  1.4754e-01,  2.4141e-01,  ...,  3.3967e-01,\n",
       "           7.6073e-01,  4.9991e-01],\n",
       "         [ 1.7047e-01, -6.1683e-01, -7.2964e-01,  ...,  8.6309e-01,\n",
       "           6.2739e-01, -3.7271e-01],\n",
       "         ...,\n",
       "         [ 6.9817e-01, -4.5541e-01, -1.7845e+00,  ...,  3.3082e-01,\n",
       "           7.0954e-02, -5.1872e-01],\n",
       "         [-9.0503e-02,  1.8623e-01, -4.4370e-01,  ...,  2.2435e-01,\n",
       "           1.8098e-01,  3.7402e-01],\n",
       "         [-8.2525e-02,  4.6579e-02, -1.5260e-01,  ..., -2.0332e-01,\n",
       "           3.3697e-01, -1.7667e-01]],\n",
       "\n",
       "        [[-3.5666e-02, -2.0223e-01, -4.1032e-01,  ...,  2.5113e-01,\n",
       "           5.8552e-02, -5.4653e-02],\n",
       "         [ 1.4298e-01,  7.4719e-02,  5.9477e-02,  ..., -2.9141e-01,\n",
       "           1.7326e-01,  4.2652e-01],\n",
       "         [ 5.7522e-01, -1.2385e+00, -5.6504e-01,  ...,  8.9952e-01,\n",
       "           4.6518e-01, -8.0804e-01],\n",
       "         ...,\n",
       "         [ 9.1570e-01, -4.1177e-01, -1.6042e+00,  ...,  1.4539e-01,\n",
       "           1.6985e-01, -2.2298e-01],\n",
       "         [-1.8156e-01,  9.9374e-03,  3.6962e-02,  ..., -2.1779e-01,\n",
       "           4.8058e-02,  3.4768e-01],\n",
       "         [-1.5242e-01, -1.0677e-01, -8.6771e-02,  ..., -1.3689e-01,\n",
       "           2.6327e-01, -3.7541e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-9.5604e-01, -1.0372e+00, -8.8754e-01,  ...,  9.0500e-02,\n",
       "          -3.8670e-01,  3.2579e-01],\n",
       "         [-3.2149e-01, -1.1213e+00, -2.3492e-01,  ..., -5.9404e-01,\n",
       "           1.8505e-01, -5.0758e-01],\n",
       "         [-4.7947e-01, -1.0745e+00, -1.7443e-01,  ..., -5.0257e-01,\n",
       "           1.2932e-01, -1.9628e-01],\n",
       "         ...,\n",
       "         [ 2.7364e-01, -4.0208e-01, -1.5246e-01,  ..., -7.0990e-01,\n",
       "          -7.4977e-01, -6.6052e-03],\n",
       "         [-1.4250e-02,  1.8744e-02, -4.9021e-02,  ..., -1.9688e-02,\n",
       "          -2.8110e-02,  1.6460e-02],\n",
       "         [-5.7646e-01, -5.5467e-01, -2.1221e-01,  ...,  2.6103e-01,\n",
       "          -4.1106e-01, -1.2234e-01]],\n",
       "\n",
       "        [[-6.1213e-01, -6.3712e-01, -8.9171e-01,  ...,  1.0260e-01,\n",
       "          -2.2410e-01,  3.3305e-01],\n",
       "         [-2.8169e-01, -6.1423e-01, -4.4993e-01,  ..., -7.2730e-01,\n",
       "           3.0354e-02, -5.1065e-01],\n",
       "         [-4.5191e-01, -2.6275e-01, -1.9171e-01,  ..., -5.4054e-01,\n",
       "          -2.1462e-01, -2.1395e-01],\n",
       "         ...,\n",
       "         [ 3.2134e-01, -2.9974e-01, -4.7083e-02,  ..., -8.0937e-01,\n",
       "          -7.8612e-01, -6.1835e-02],\n",
       "         [ 4.3050e-02,  2.1942e-02, -2.1436e-02,  ...,  1.9552e-02,\n",
       "          -3.5334e-02,  7.2242e-03],\n",
       "         [-5.9901e-02, -6.3968e-01, -6.0082e-01,  ...,  4.2177e-01,\n",
       "          -5.1704e-01, -1.6159e-01]],\n",
       "\n",
       "        [[-4.9645e-01, -1.8308e-01, -5.2315e-01,  ..., -1.9021e-01,\n",
       "           3.7380e-01,  3.9644e-01],\n",
       "         [-1.3227e-01, -2.7622e-01, -3.4954e-01,  ..., -4.5666e-01,\n",
       "           3.7865e-01, -1.0961e-01],\n",
       "         [-3.6261e-01, -4.0016e-01,  6.7574e-02,  ..., -3.2071e-01,\n",
       "          -2.7090e-01, -3.0042e-01],\n",
       "         ...,\n",
       "         [ 2.9609e-01, -2.8563e-01, -3.8183e-02,  ..., -6.0557e-01,\n",
       "          -5.1633e-01,  2.0051e-01],\n",
       "         [ 4.8782e-01, -9.0928e-02, -2.3581e-01,  ..., -1.7198e-03,\n",
       "          -5.9445e-01, -2.4313e-01],\n",
       "         [-2.5167e-01, -3.5192e-01, -4.6880e-01,  ...,  2.5005e-01,\n",
       "           3.3591e-02, -2.6271e-01]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVzRfvkbe-Yp"
   },
   "source": [
    "Switch around the \"layers\" and \"tokens\" dimensions with `permute`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AtDVE58cdeYp",
    "outputId": "594d50ca-c34c-4af3-c9ea-f2da11dd72d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 13, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swap dimensions 0 and 1.\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ey5RhOQ7NGtz"
   },
   "source": [
    "### 3.3. Creating word and sentence vectors from hidden states\n",
    "\n",
    "What do we do with these hidden states? \n",
    "\n",
    "We would like to get individual vectors for each tokens, or a single vector representation of the whole sentence.\n",
    "\n",
    "But for each token, we have 13 separate vectors each of length 768.\n",
    "\n",
    "In order to get the individual vectors we will need to combine some of the layer vectors, but which layer or combination of layers provides the best representation?\n",
    "\n",
    "There's no single answer, but there's two reasonable approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76TdtFH8NM9q"
   },
   "source": [
    "#### Word Vectors\n",
    "\n",
    "First, let's **concatenate** the last four layers, giving us a single word vector per token. Each vector will have length `4 x 768 = 3,072`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pv42h9jANMRf",
    "outputId": "f6278775-ba50-47da-aefc-55c8f558932d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 22 x 3072\n"
     ]
    }
   ],
   "source": [
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last\n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "\n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnWaByfelM-e"
   },
   "source": [
    "As an alternative method, let's try creating the word vectors by **summing** together the last four layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j4DKDtFwiF0S",
    "outputId": "c8175c53-306a-4bda-8db3-2ec0f17669e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 22 x 768\n"
     ]
    }
   ],
   "source": [
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "\n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQaco6jRLkXn"
   },
   "source": [
    "### Sentence Vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuul6iQqnXT2"
   },
   "source": [
    "\n",
    "To get a single vector for our entire sentence we have multiple application-dependent strategies, but a simple approach is to average the second to last hiden layer of each token producing a single 768 length vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Zn0n2S-FWZih"
   },
   "outputs": [],
   "source": [
    "# `hidden_states` has shape [13 x 1 x 22 x 768]\n",
    "\n",
    "# `token_vecs` is a tensor with shape [22 x 768]\n",
    "token_vecs = hidden_states[-2][0]\n",
    "\n",
    "# Calculate the average of all 22 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "MQv0FL8VWadn",
    "outputId": "9fce910b-f15c-4545-fc0e-8d75e656f237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final sentence embedding vector of shape: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqYcrAipfE3E"
   },
   "source": [
    "### 3.4. Confirming contextually dependent vectors\n",
    "\n",
    "To confirm that the value of these vectors are in fact contextually dependent, let's look at the different instances of the word \"bank\" in our example sentence:\n",
    "\n",
    "\"After stealing money from the **bank vault**, the **bank robber** was seen fishing on the Mississippi **river bank**.\"\n",
    "\n",
    "Let's find the index of those three instances of the word \"bank\" in the example sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNiRsEh9cmWz",
    "outputId": "260d8774-4ade-4ebb-c7df-9a3a1c1fdd9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 after\n",
      "2 stealing\n",
      "3 money\n",
      "4 from\n",
      "5 the\n",
      "6 bank\n",
      "7 vault\n",
      "8 ,\n",
      "9 the\n",
      "10 bank\n",
      "11 robber\n",
      "12 was\n",
      "13 seen\n",
      "14 fishing\n",
      "15 on\n",
      "16 the\n",
      "17 mississippi\n",
      "18 river\n",
      "19 bank\n",
      "20 .\n",
      "21 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, token_str in enumerate(tokenized_text):\n",
    "  print (i, token_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEhBIA5RlS8-"
   },
   "source": [
    "They are at 6, 10, and 19.\n",
    "\n",
    "For this analysis, we'll use the word vectors that we created by summing the last four layers.\n",
    "\n",
    "We can try printing out their vectors to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tBa6vRHknSkv",
    "outputId": "103bb7de-e7c4-45a5-b0c9-991a15604956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 vector values for each instance of \"bank\".\n",
      "\n",
      "bank vault    tensor([ 3.3596, -2.9805, -1.5421,  0.7065,  2.0031])\n",
      "bank robber   tensor([ 2.7359, -2.5577, -1.3094,  0.6797,  1.6633])\n",
      "river bank    tensor([ 1.5266, -0.8895, -0.5152, -0.9298,  2.8334])\n"
     ]
    }
   ],
   "source": [
    "print('First 5 vector values for each instance of \"bank\".')\n",
    "print('')\n",
    "print(\"bank vault   \", str(token_vecs_sum[6][:5]))\n",
    "print(\"bank robber  \", str(token_vecs_sum[10][:5]))\n",
    "print(\"river bank   \", str(token_vecs_sum[19][:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ca2TCQ_G7SM3"
   },
   "source": [
    "We can see that the values differ, but let's calculate the cosine similarity between the vectors to make a more precise comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eYXUwiG0yhBS",
    "outputId": "d2b5d681-a1ce-44e5-8c52-fe6b57e09392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector similarity for  *similar*  meanings:  0.94\n",
      "Vector similarity for *different* meanings:  0.69\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Calculate the cosine similarity between the word bank\n",
    "# in \"bank robber\" vs \"river bank\" (different meanings).\n",
    "diff_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[19])\n",
    "\n",
    "# Calculate the cosine similarity between the word bank\n",
    "# in \"bank robber\" vs \"bank vault\" (same meaning).\n",
    "same_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[6])\n",
    "\n",
    "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
    "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7jroXfKspe_"
   },
   "source": [
    "This looks pretty good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orjhWUJgmxo5"
   },
   "source": [
    "### 3.5. Pooling Strategy & Layer Choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1CI97kNn8dD"
   },
   "source": [
    "Below are a couple additional resources for exploring this topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3D5qnRNmq5_"
   },
   "source": [
    "**BERT Authors**\n",
    "\n",
    "The BERT authors tested word-embedding strategies by feeding different vector combinations as input features to a BiLSTM used on a named entity recognition task and observing the resulting F1 scores.\n",
    "\n",
    "(Image from [Jay Allamar](http://jalammar.github.io/illustrated-bert/)'s blog)\n",
    "\n",
    "\n",
    "![alt text](http://jalammar.github.io/images/bert-feature-extraction-contextualized-embeddings.png)\n",
    "\n",
    "While concatenation of the last four layers produced the best results on this specific task, many of the other methods come in a close second and in general it is advisable to test different versions for your specific application: results may vary.\n",
    "\n",
    "This is partially demonstrated by noting that the different layers of BERT encode very different kinds of information, so the appropriate pooling strategy will change depending on the application because different layers encode different kinds of information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7_CVgejm5pr"
   },
   "source": [
    "**Han Xiao's BERT-as-service**\n",
    "\n",
    "Han Xiao created an open-source project named [bert-as-service](https://github.com/hanxiao/bert-as-service) on GitHub which is intended to create word embeddings for your text using BERT. Han experimented with different approaches to combining these embeddings, and shared some conclusions and rationale on the [FAQ page](https://github.com/hanxiao/bert-as-service#speech_balloon-faq) of the project.\n",
    "\n",
    "`bert-as-service`, by default, uses the outputs from the **second-to-last layer** of the model.\n",
    "\n",
    "I would summarize Han's perspective by the following:\n",
    "\n",
    "1. The embeddings start out in the first layer as having no contextual information (i.e., the meaning of the initial 'bank' embedding isn't specific to river bank or financial bank).\n",
    "2. As the embeddings move deeper into the network, they pick up more and more contextual information with each layer.\n",
    "3. As you approach the final layer, however, you start picking up information that is specific to BERT's pre-training tasks (the \"Masked Language Model\" (MLM) and \"Next Sentence Prediction\" (NSP)).\n",
    "    * What we want is embeddings that encode the word meaning well...\n",
    "    * BERT is motivated to do this, but it is also motivated to encode anything else that would help it determine what a missing word is (MLM), or whether the second sentence came after the first (NSP).\n",
    "4. The second-to-last layer is what Han settled on as a reasonable sweet-spot.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "038b3b6907df47d186eaa618b27c9e01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0eff92cf040f48e686e342701c8433be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11cc2d4721be49faa7c05532b5afd4af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14162301f7714988b042483e1684b2df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1c4976bcfa6c484b834b7b4c89f32207": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d69c12e99b647ef819fad6fcda7f0de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f1266849551443f28bf5d182b8a8ebda",
       "IPY_MODEL_4740320adcbc4293ba4f48423d10d176",
       "IPY_MODEL_1d9c8b62fe7143429369d949f8e45bcb"
      ],
      "layout": "IPY_MODEL_a3e98e707b4644bb814406d465c44278"
     }
    },
    "1d9c8b62fe7143429369d949f8e45bcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c943e8fa7d64e8f92a96bba3ca7a3cc",
      "placeholder": "",
      "style": "IPY_MODEL_21bedfc6869046d8bc8af6784bf2905b",
      "value": "48.0/48.0[00:00&lt;00:00,1.01kB/s]"
     }
    },
    "21bedfc6869046d8bc8af6784bf2905b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "269216a76cec47da99d4102861b415a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "27912c81ca164a91b8ee2a3c31ced444": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33d034013cc04b9dbb792d259725086f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "38245b96fde64341bcda116bb0c9a8b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcd1a84e56a34e2f9d32969982e8f8a4",
      "placeholder": "",
      "style": "IPY_MODEL_0eff92cf040f48e686e342701c8433be",
      "value": "232k/232k[00:00&lt;00:00,3.88MB/s]"
     }
    },
    "39180b1a2c4d448e8ed5531f5dd95f8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "391a563da8974a59b5cc3b29d38da133": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4eca4af3dbb74c1eba5b212ee967def7",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_038b3b6907df47d186eaa618b27c9e01",
      "value": 231508
     }
    },
    "4141fcb79a8645ff8486410d2cb297ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4740320adcbc4293ba4f48423d10d176": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4141fcb79a8645ff8486410d2cb297ab",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_47c5ac5b052443b488ce7c93622b594f",
      "value": 48
     }
    },
    "47c5ac5b052443b488ce7c93622b594f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4852502fc965406f96fcea54d8043dba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5400adc121494e9b85492d23e8916941",
      "placeholder": "",
      "style": "IPY_MODEL_ec1da44c139c402f8ca9493e8ca7e076",
      "value": "tokenizer.json:100%"
     }
    },
    "48a392d96be64c2abda1de1f93b5c930": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a6b7b9a9fad46f8928b53fc63033047": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbd45bf1a1a64e5dabd2560af2128ba5",
      "placeholder": "",
      "style": "IPY_MODEL_d35047bf8f584528a0115bbe0ef945ad",
      "value": "440M/440M[00:02&lt;00:00,175MB/s]"
     }
    },
    "4c943e8fa7d64e8f92a96bba3ca7a3cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4eca4af3dbb74c1eba5b212ee967def7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fddf1e099df41c396d79cdab4871c71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5400adc121494e9b85492d23e8916941": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "548880bd58b74595816ad35671d48eaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a26def309f6a4d1fb4a52b97f75a3dda",
      "placeholder": "",
      "style": "IPY_MODEL_33d034013cc04b9dbb792d259725086f",
      "value": "570/570[00:00&lt;00:00,10.6kB/s]"
     }
    },
    "57f7de73a87c47c0a1e80a981da09297": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4852502fc965406f96fcea54d8043dba",
       "IPY_MODEL_eaf4f4bf3ff84f9d90a1f01f0e25a45c",
       "IPY_MODEL_ade4e04af73c463b8ba128227e9923e7"
      ],
      "layout": "IPY_MODEL_4fddf1e099df41c396d79cdab4871c71"
     }
    },
    "5b4ef18f04cf4e01afab3dbb243273bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "646fe8a8ebb2489193d7ad6032e99950": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "721613d206ff42a6a5e177e89793748c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e557e740d2994c27a3d2513df8311217",
      "placeholder": "",
      "style": "IPY_MODEL_b113e12db4c042c0b1494aaa03a78793",
      "value": "vocab.txt:100%"
     }
    },
    "72f21ea582194c73acc2cb1980d76b48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f51ceacda4c4b75a9df6ab43afe9df9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_721613d206ff42a6a5e177e89793748c",
       "IPY_MODEL_391a563da8974a59b5cc3b29d38da133",
       "IPY_MODEL_38245b96fde64341bcda116bb0c9a8b5"
      ],
      "layout": "IPY_MODEL_72f21ea582194c73acc2cb1980d76b48"
     }
    },
    "8385d43710df4b228bdaa01fe594bf8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_646fe8a8ebb2489193d7ad6032e99950",
      "placeholder": "",
      "style": "IPY_MODEL_11cc2d4721be49faa7c05532b5afd4af",
      "value": "config.json:100%"
     }
    },
    "83f26150c1c846b0834138bc3cf09f80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27912c81ca164a91b8ee2a3c31ced444",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8df713d63e5249f3956003e0b8583833",
      "value": 440449768
     }
    },
    "88ecf850c0e946e58e5fb150f9e163ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c4976bcfa6c484b834b7b4c89f32207",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14162301f7714988b042483e1684b2df",
      "value": 570
     }
    },
    "8c73e03d59c64595a835747550e520a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8df713d63e5249f3956003e0b8583833": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "98f29b52392e4360a6f8d07c50064cde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99dada16ccc0406fa64464145be74a4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a26def309f6a4d1fb4a52b97f75a3dda": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3e98e707b4644bb814406d465c44278": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac1a9eda3fe441638a55fd83cdde83ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_db9c604c6c0f42dbb4569f8e47238822",
       "IPY_MODEL_83f26150c1c846b0834138bc3cf09f80",
       "IPY_MODEL_4a6b7b9a9fad46f8928b53fc63033047"
      ],
      "layout": "IPY_MODEL_fcb1c69295e34a0dbb84721213cafb0b"
     }
    },
    "ade4e04af73c463b8ba128227e9923e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb83d6f0bb90456489c47f2c391c24d1",
      "placeholder": "",
      "style": "IPY_MODEL_b44f74006e9c431bb9fe84a9b6aa241a",
      "value": "466k/466k[00:00&lt;00:00,6.58MB/s]"
     }
    },
    "b113e12db4c042c0b1494aaa03a78793": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b44f74006e9c431bb9fe84a9b6aa241a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb83d6f0bb90456489c47f2c391c24d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1ce9d63b03f420e828dd1017fe9cee3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8385d43710df4b228bdaa01fe594bf8e",
       "IPY_MODEL_88ecf850c0e946e58e5fb150f9e163ee",
       "IPY_MODEL_548880bd58b74595816ad35671d48eaf"
      ],
      "layout": "IPY_MODEL_98f29b52392e4360a6f8d07c50064cde"
     }
    },
    "d35047bf8f584528a0115bbe0ef945ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db9c604c6c0f42dbb4569f8e47238822": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b4ef18f04cf4e01afab3dbb243273bb",
      "placeholder": "",
      "style": "IPY_MODEL_8c73e03d59c64595a835747550e520a0",
      "value": "model.safetensors:100%"
     }
    },
    "dcd1a84e56a34e2f9d32969982e8f8a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e557e740d2994c27a3d2513df8311217": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eaf4f4bf3ff84f9d90a1f01f0e25a45c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99dada16ccc0406fa64464145be74a4b",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_269216a76cec47da99d4102861b415a6",
      "value": 466062
     }
    },
    "ec1da44c139c402f8ca9493e8ca7e076": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f1266849551443f28bf5d182b8a8ebda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39180b1a2c4d448e8ed5531f5dd95f8d",
      "placeholder": "",
      "style": "IPY_MODEL_48a392d96be64c2abda1de1f93b5c930",
      "value": "tokenizer_config.json:100%"
     }
    },
    "fbd45bf1a1a64e5dabd2560af2128ba5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcb1c69295e34a0dbb84721213cafb0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
